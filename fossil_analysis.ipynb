{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting patterns of speciation in the fos- sil record\n",
    "\n",
    "In this assignment, we use data from the NOW (New and Old Worlds) database of fossil mammals to study patterns of speciation over time and space. In particular, we are interested to know when and where speciation rates have been significantly high. The task is to find which time periods and which places over the history of mammals have given rise to exceptionally high numbers of new species. The phenomenon is known in the evolutionary literature as the “species factory”. Palaeontologists are interested why and in which ways those times and places are special. The role of computational science is to identify and characterize such times and places.\n",
    "We practice using pandas DataFrames, performing logistic regression and making statistical significance tests in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:20.964314Z",
     "start_time": "2022-02-15T13:28:20.949340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 1.</h3>\n",
    "Data saved in folder as fossils.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 2.</h3>\n",
    "Loading from text file into DataFrame, then to csv. File has 68507 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:25.092519Z",
     "start_time": "2022-02-15T13:28:25.079642Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def from_text_to_frame_to_csv(filename,save=True):\n",
    "    #open as usual, declare file object and colum names\n",
    "    with  open(filename, 'r') as file:\n",
    "        data = file.readlines()\n",
    "        columns = data[0].split('\\t')\n",
    "        rows = []\n",
    "        \n",
    "        #iterate through rows with regex substitution, split by tabs\n",
    "        #csv format null is made empty for later use\n",
    "        for row in data[1:]:\n",
    "            cells = row.split('\\t')\n",
    "            rows.append(cells)\n",
    "        \n",
    "        #combine into dataframe, but mark empty rows as string 'empty'\n",
    "        #since it will be inserted into csv later\n",
    "        fossil_frame = pd.DataFrame(rows,columns=columns)\n",
    "        output_file = filename.split('.')[0]+'.csv'\n",
    "        if save: fossil_frame.to_csv(output_file,sep='\\t',index=False)\n",
    "        print('This DataFrame has {} rows'.format(len(fossil_frame)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:25.569952Z",
     "start_time": "2022-02-15T13:28:25.567215Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'fossils.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:33.726120Z",
     "start_time": "2022-02-15T13:28:26.512465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This DataFrame has 68507 rows\n"
     ]
    }
   ],
   "source": [
    "from_text_to_frame_to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T11:23:36.276487Z",
     "start_time": "2022-02-08T11:23:36.265895Z"
    }
   },
   "source": [
    "<h3>Exercise 3. a)</h3>\n",
    "a) Remove all rows where LAT = LONG = 0; these occurrences have incorrect coordinates. Drop rows where SPECIES is “sp.” or “indet.”; these occurrences have not been properly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:37.463721Z",
     "start_time": "2022-02-15T13:28:36.536873Z"
    }
   },
   "outputs": [],
   "source": [
    "fossil_frame = pd.read_csv('fossils.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:55.910319Z",
     "start_time": "2022-02-15T13:28:55.896958Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_latlong_zeros_species_spindet(frame):\n",
    "    no_zero_latlong = frame[(frame['LAT'] == 0) & (frame['LONG'] == 0)].index\n",
    "    frame = frame[~(frame.index.isin(no_zero_latlong))]\n",
    "    frame = frame[~(frame['SPECIES'].isin(['sp.','indet.']))]\n",
    "    check_sum_latlong = frame[(frame['LAT'] == 0) &(frame['LONG'] == 0)].sum().sum()\n",
    "    check_sum_species = frame[(frame['SPECIES'].isin(['sp.','indet.']))].sum().sum()\n",
    "    print(f\"Frame filtered of 'LAT' and 'LONG' equals 0. Sum of values containg is: {check_sum_latlong}\")\n",
    "    print(f\"Frame filtered of 'SPECIES' = 'sp.','indet.' Sum of values containg is: {check_sum_species}\")\n",
    "    return frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:56.516332Z",
     "start_time": "2022-02-15T13:28:56.233961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame filtered of 'LAT' and 'LONG' equals 0. Sum of values containg is: 0.0\n",
      "Frame filtered of 'SPECIES' = 'sp.','indet.' Sum of values containg is: 0.0\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = no_latlong_zeros_species_spindet(fossil_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T12:00:21.863883Z",
     "start_time": "2022-02-14T12:00:21.853693Z"
    }
   },
   "source": [
    "<h3>Exercise 3. b)</h3>\n",
    "Next we will assign each occurrence to a specific Mammal Neogene\n",
    "(MN) time unit. Table 1 shows the time boundaries of each time unit.\n",
    "Assign each occurrence to a correct time unit by calculating the mean of\n",
    "MIN AGE and MAX AGE. If the mean age of an occurrence is precisely\n",
    "on the boundary between two time units, assign the occurrence to the\n",
    "older time unit. If the mean age of an occurrence is outside of the MN\n",
    "time interval, assign it to a “pre-MN” or “post-MN” category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:28:59.550453Z",
     "start_time": "2022-02-15T13:28:59.529520Z"
    }
   },
   "outputs": [],
   "source": [
    "def MN_frame(frame):\n",
    "    labels = ['MQ19','MQ18','MN17','MN16','MN15','MN14','MN13','MN12','MN11','MN10','MN9','MN7-8','MN6','MN5','MN4','MN3','MN2','MN1']\n",
    "    bins = [0.01,0.85,1.9,2.5,3.55,5,5.3,7.1,7.6,8.9,9.9,11.2,12.85,14.2,16.4,17.2,19.5,21.7,23]\n",
    "    frame['MEAN_AGE'] = frame[['MAX_AGE','MIN_AGE']].mean(axis=1)\n",
    "    subset = frame[(frame['MEAN_AGE'] >= .01 ) & (frame['MEAN_AGE'] <= 23 )]['MEAN_AGE']\n",
    "    frame['MN'] = pd.cut(subset,bins=bins,labels=labels)\n",
    "    frame['MN'] = frame['MN'].astype(str)\n",
    "    frame.loc[frame['MEAN_AGE'] < .01,'MN'] = 'post-MN'\n",
    "    frame.loc[frame['MEAN_AGE'] > 23,'MN'] = 'pre-MN'\n",
    "    labels.append('pre-MN')\n",
    "    labels.insert (0, \"post-MN\") \n",
    "    print('Values check out:\\n{}'.format(frame.groupby('MN').aggregate({'MEAN_AGE':['max','min']}).reindex(labels)))\n",
    "    return frame.drop(columns=['MEAN_AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:05.760671Z",
     "start_time": "2022-02-15T13:29:05.376600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values check out:\n",
      "          MEAN_AGE           \n",
      "               max        min\n",
      "MN                           \n",
      "post-MN   0.005850   0.005850\n",
      "MQ19      0.850000   0.011500\n",
      "MQ18      1.865000   0.865000\n",
      "MN17      2.500000   1.915075\n",
      "MN16      3.550000   2.520000\n",
      "MN15      5.000000   3.566500\n",
      "MN14      5.300000   5.040000\n",
      "MN13      7.100000   5.350000\n",
      "MN12      7.600000   7.110000\n",
      "MN11      8.854500   7.818000\n",
      "MN10      9.861500   8.938000\n",
      "MN9      11.167000   9.921900\n",
      "MN7-8    12.805000  11.215000\n",
      "MN6      14.200000  13.000000\n",
      "MN5      16.393625  14.270000\n",
      "MN4      17.200000  16.405500\n",
      "MN3      19.478500  17.235000\n",
      "MN2      21.400000  19.700000\n",
      "MN1      22.860000  21.735000\n",
      "pre-MN   65.935000  23.025333\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = MN_frame(fossil_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. c)</h3>\n",
    "\n",
    "Sometimes expert knowledge may be used to override some of the\n",
    "information recorded in the data. In our case, experts in palaeontology\n",
    "tell us that occurrences in the localities “Samos Main Bone Beds” and\n",
    "“Can Llobateres I” should be assigned to time units MN12 and MN9,\n",
    "respectively. Check these and if necessary, edit the time units to their\n",
    "correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:10.501737Z",
     "start_time": "2022-02-15T13:29:10.494156Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_locality_mn(frame):\n",
    "    frame.loc[frame['NAME'] == 'Samos Main Bone Beds','MN'] = 'MN12'\n",
    "    frame.loc[frame['NAME'] == 'Can Llobateres 1','MN'] = 'MN9'\n",
    "    check_sum_Llobateres = frame[frame['NAME']== 'Can Llobateres 1']['MN'].value_counts()\n",
    "    check_sum_Samos = frame[frame['NAME']== 'Samos Main Bone Beds']['MN'].value_counts()\n",
    "    print(f'Age bracket count for locality named \"Can Llobateres 1\": {check_sum_Llobateres}\"')\n",
    "    print(f'Age bracket count for locality named \"Samos Main Bone Beds\": {check_sum_Samos}\"')\n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:11.858790Z",
     "start_time": "2022-02-15T13:29:11.802388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age bracket count for locality named \"Can Llobateres 1\": MN9    76\n",
      "Name: MN, dtype: int64\"\n",
      "Age bracket count for locality named \"Samos Main Bone Beds\": MN12    52\n",
      "Name: MN, dtype: int64\"\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = translate_locality_mn(fossil_frame) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. d)</h3>\n",
    "\n",
    "We need to be able to identify all occurrences of each species. Assign\n",
    "a unique identification number for each unique combination of GENUS\n",
    "and SPECIES. Create a new column in the DataFrame and labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:15.725898Z",
     "start_time": "2022-02-15T13:29:15.714223Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_spec_id_create(frame):\n",
    "    frame['GEN_SPEC'] = (frame['GENUS'] +' '+frame['SPECIES']).str.lower()\n",
    "    gen_pointers = pd.Series(frame['GEN_SPEC'].unique()).to_dict()\n",
    "    new_gen_pointers = {y:x for x,y in gen_pointers.items()}\n",
    "    frame['GEN_SPEC_ID'] = [new_gen_pointers[i] for i in frame['GEN_SPEC'].values]\n",
    "    check_sums = len(test['GEN_SPEC_ID'].unique())\n",
    "    print(f'successfully created {check_sums} unique index numbers for columns: GENUS, SPECIES')\n",
    "    return frame.drop(columns=['GEN_SPEC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:16.588091Z",
     "start_time": "2022-02-15T13:29:16.251112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully created 9926 unique index numbers for columns: GENUS, SPECIES\n"
     ]
    }
   ],
   "source": [
    " fossil_frame = gen_spec_id_create(fossil_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. e)</h3>\n",
    "\n",
    "Each locality should contain no more than one occurrence of any\n",
    "species. Check whether this is the case and remove duplicate copies, if\n",
    "necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:26.005747Z",
     "start_time": "2022-02-15T13:29:25.995172Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_dup_species(frame):\n",
    "    check_counts = frame.groupby('NAME').aggregate({'GEN_SPEC_ID':'count'}).sum().sum()\n",
    "    check_unique = frame.groupby('NAME').aggregate({'GEN_SPEC_ID':'nunique'}).sum().sum()\n",
    "    if check_counts > check_unique: \n",
    "        frame = frame.drop_duplicates(subset=['NAME','GEN_SPEC_ID'])\n",
    "        print(f'{check_counts - check_unique} duplicates found. duplicates removed.')\n",
    "    else:\n",
    "        print('no duplicates found')\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:29:27.171648Z",
     "start_time": "2022-02-15T13:29:27.003567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 duplicates found. duplicates removed.\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = drop_dup_species(fossil_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. f )</h3>\n",
    "\n",
    "How many rows are we left with in the DataFrame (compare with\n",
    "exercise 2)? How many unique species and localities are identified?\n",
    "\n",
    "<ul>\n",
    "    <li>original frame: 68507 rows</li>\n",
    "    <li>new frame: 50056 rows</li>\n",
    "    <li>unique localities: 5624 values</li>\n",
    "    <li>unique species (combined value of species name and genus): 9926 values</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:44:22.639457Z",
     "start_time": "2022-02-15T13:44:22.631005Z"
    }
   },
   "outputs": [],
   "source": [
    "def frame_summary(frame):\n",
    "    print('Original data frame has:')\n",
    "    from_text_to_frame_to_csv(filename,save=False)\n",
    "    print(f'New Dataframe has {len(frame)} rows')\n",
    "    aggregates = frame.aggregate({'NAME':'nunique','GEN_SPEC_ID':'nunique'}).to_dict()\n",
    "    n_localities,n_genid = aggregates['NAME'],aggregates['GEN_SPEC_ID']\n",
    "    print(f'Locality name has {n_localities} unique values')\n",
    "    print(f'Species (Species Name, Genus) has {n_genid} values')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T13:44:26.313579Z",
     "start_time": "2022-02-15T13:44:22.871922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data frame has:\n",
      "This DataFrame has 68507 rows\n",
      "New Dataframe has 50056 rows\n",
      "Locality name has 5624 unique values\n",
      "Species (Species Name, Genus) has 9926 values\n"
     ]
    }
   ],
   "source": [
    "frame_summary(fossil_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
