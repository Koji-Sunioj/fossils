{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting patterns of speciation in the fos- sil record\n",
    "\n",
    "In this assignment, we use data from the NOW (New and Old Worlds) database of fossil mammals to study patterns of speciation over time and space. In particular, we are interested to know when and where speciation rates have been significantly high. The task is to find which time periods and which places over the history of mammals have given rise to exceptionally high numbers of new species. The phenomenon is known in the evolutionary literature as the “species factory”. Palaeontologists are interested why and in which ways those times and places are special. The role of computational science is to identify and characterize such times and places.\n",
    "We practice using pandas DataFrames, performing logistic regression and making statistical significance tests in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T11:44:24.801132Z",
     "start_time": "2022-02-14T11:44:24.795177Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 1.</h3>\n",
    "Data saved in folder as fossils.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise 2.</h3>\n",
    "Loading from text file into DataFrame, then to csv. File has 68507 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T11:45:53.237749Z",
     "start_time": "2022-02-14T11:45:53.228094Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def from_text_to_frame_to_csv(filename):\n",
    "    #open as usual, declare file object and colum names\n",
    "    with  open(filename, 'r') as file:\n",
    "        data = file.readlines()\n",
    "        columns = data[0].replace('\\t',' ').split()\n",
    "        rows = []\n",
    "        \n",
    "        #iterate through rows with regex substitution, split by tabs\n",
    "        #csv format null is made empty for later use\n",
    "        for row in data[1:]:\n",
    "            cells = row.split('\\t')\n",
    "            rows.append(cells)\n",
    "        \n",
    "        #combine into dataframe, but mark empty rows as string 'empty'\n",
    "        #since it will be inserted into csv later\n",
    "        fossil_frame = pd.DataFrame(rows,columns=columns)\n",
    "        print('This DataFrame has {} rows'.format(len(fossil_frame)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T11:45:53.930679Z",
     "start_time": "2022-02-14T11:45:53.924989Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'fossils.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:10:14.950002Z",
     "start_time": "2022-02-14T14:10:09.588816Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This DataFrame has 68507 rows\n"
     ]
    }
   ],
   "source": [
    "from_text_to_frame_to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T11:23:36.276487Z",
     "start_time": "2022-02-08T11:23:36.265895Z"
    }
   },
   "source": [
    "<h3>Exercise 3. a)</h3>\n",
    "a) Remove all rows where LAT = LONG = 0; these occurrences have incorrect coordinates. Drop rows where SPECIES is “sp.” or “indet.”; these occurrences have not been properly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:11:24.902812Z",
     "start_time": "2022-02-14T14:11:23.885852Z"
    }
   },
   "outputs": [],
   "source": [
    "fossil_frame = pd.read_csv('fossils.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:11:25.386508Z",
     "start_time": "2022-02-14T14:11:25.373791Z"
    }
   },
   "outputs": [],
   "source": [
    "def no_latlong_zeros_species_spindet(frame):\n",
    "    no_zero_latlong = frame[(frame['LAT'] == 0) & (frame['LONG'] == 0)].index\n",
    "    frame = frame[~(frame.index.isin(no_zero_latlong))]\n",
    "    frame = frame[~(frame['SPECIES'].isin(['sp.','indet.']))]\n",
    "    check_sum_latlong = frame[(frame['LAT'] == 0) &(frame['LONG'] == 0)].sum().sum()\n",
    "    check_sum_species = frame[(frame['SPECIES'].isin(['sp.','indet.']))].sum().sum()\n",
    "    print(f\"Frame filtered of 'LAT' and 'LONG' equals 0. Sum of values containg is: {check_sum_latlong}\")\n",
    "    print(f\"Frame filtered of Species 'sp.' and 'indet.' Sum of values containg is: {check_sum_species}\")\n",
    "    return frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:11:34.354272Z",
     "start_time": "2022-02-14T14:11:34.093409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame filtered of 'LAT' and 'LONG' equals 0. Sum of values containg is: 0.0\n",
      "Frame filtered of Species 'sp.' and 'indet.' Sum of values containg is: 0.0\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = no_latlong_zeros_species_spindet(fossil_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T12:00:21.863883Z",
     "start_time": "2022-02-14T12:00:21.853693Z"
    }
   },
   "source": [
    "<h3>Exercise 3. b)</h3>\n",
    "Next we will assign each occurrence to a specific Mammal Neogene\n",
    "(MN) time unit. Table 1 shows the time boundaries of each time unit.\n",
    "Assign each occurrence to a correct time unit by calculating the mean of\n",
    "MIN AGE and MAX AGE. If the mean age of an occurrence is precisely\n",
    "on the boundary between two time units, assign the occurrence to the\n",
    "older time unit. If the mean age of an occurrence is outside of the MN\n",
    "time interval, assign it to a “pre-MN” or “post-MN” category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:11:36.509423Z",
     "start_time": "2022-02-14T14:11:36.493946Z"
    }
   },
   "outputs": [],
   "source": [
    "def MN_frame(frame):\n",
    "    labels = ['MQ19','MQ18','MN17','MN16','MN15','MN14','MN13','MN12','MN11','MN10','MN9','MN7-8','MN6','MN5','MN4','MN3','MN2','MN1']\n",
    "    bins = [0.01,0.85,1.9,2.5,3.55,5,5.3,7.1,7.6,8.9,9.9,11.2,12.85,14.2,16.4,17.2,19.5,21.7,23]\n",
    "    frame['MEAN_AGE'] = frame[['MAX_AGE','MIN_AGE']].mean(axis=1)\n",
    "    subset = frame[(frame['MEAN_AGE'] >= .01 ) & (frame['MEAN_AGE'] <= 23 )]['MEAN_AGE']\n",
    "    frame['MN'] = pd.cut(subset,bins=bins,labels=labels)\n",
    "    frame['MN'] = frame['MN'].astype(str)\n",
    "    frame.loc[frame['MEAN_AGE'] < .01,'MN'] = 'post-MN'\n",
    "    frame.loc[frame['MEAN_AGE'] > 23,'MN'] = 'pre-MN'\n",
    "    labels.append('pre-MN')\n",
    "    labels.insert (0, \"post-MN\") \n",
    "    print('Values check out:\\n{}'.format(frame.groupby('MN').aggregate({'MEAN_AGE':['max','min']}).reindex(labels)))\n",
    "    return frame.drop(columns=['MEAN_AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-14T14:11:37.646909Z",
     "start_time": "2022-02-14T14:11:37.343134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values check out:\n",
      "          MEAN_AGE           \n",
      "               max        min\n",
      "MN                           \n",
      "post-MN   0.005850   0.005850\n",
      "MQ19      0.850000   0.011500\n",
      "MQ18      1.865000   0.865000\n",
      "MN17      2.500000   1.915075\n",
      "MN16      3.550000   2.520000\n",
      "MN15      5.000000   3.566500\n",
      "MN14      5.300000   5.040000\n",
      "MN13      7.100000   5.350000\n",
      "MN12      7.600000   7.110000\n",
      "MN11      8.854500   7.818000\n",
      "MN10      9.861500   8.938000\n",
      "MN9      11.167000   9.921900\n",
      "MN7-8    12.805000  11.215000\n",
      "MN6      14.200000  13.000000\n",
      "MN5      16.393625  14.270000\n",
      "MN4      17.200000  16.405500\n",
      "MN3      19.478500  17.235000\n",
      "MN2      21.400000  19.700000\n",
      "MN1      22.860000  21.735000\n",
      "pre-MN   65.935000  23.025333\n"
     ]
    }
   ],
   "source": [
    "fossil_frame = MN_frame(fossil_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
